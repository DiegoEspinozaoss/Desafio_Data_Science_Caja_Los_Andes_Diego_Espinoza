{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e99d605e",
   "metadata": {},
   "source": [
    "Caso 1:\n",
    "Imagine que ud es un data scientist y le piden que realice un modelo de clasificaci√≥n binaria utilizando solamente una t√©cnica, dada la urgencia. Si eliges este caso, a continuaci√≥n se comparte un dataset en el siguiente link y responda las preguntas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b73d69f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x1        x2   x3     x4  x5  x6  x7   x8  target\n",
      "0   50.1341 -326.0000  SAT  MZBER   0   0   6 -6.5       0\n",
      "1   50.1341 -326.0000  SAT  MZBER   0   0   6 -4.5       0\n",
      "2  124.3276 -275.1935  LCV  MZBER   0   0   3 -2.5       0\n",
      "3   50.1341 -326.0000  SAT  MZBER   0   0   3 -4.5       0\n",
      "4   85.3905 -298.8632  XJB  MZBER   0   0   5 -4.5       0\n",
      "Cantidad de valores diferentes en x3: 4\n",
      "Cantidad de valores diferentes en x4: 4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Primero que todo cargo mi archivo dataset_Caso_1.csv\n",
    "df = pd.read_csv(\"dataset_Caso_1.csv\")\n",
    "\n",
    "#Luego visualizo adecuadamente cada tipo de datos que contiene cada columna viendo el encabezado de las mismas\n",
    "print(df.head())\n",
    "\n",
    "#primero que todo nos cercioramos de que en efecto, como nos dice el enunciado, la columna\n",
    "#target solamente contenga dos valores (es decir, es una variable binaria)\n",
    "# df['target'][df['target']==1]\n",
    "\n",
    "#por √∫ltimo imprimo tambi√©n las propia dataframe\n",
    "df\n",
    "\n",
    "\n",
    "#vemos adem√°s la cantidad de valores diferentes en las columnas que contienen variables categ√≥ricas\n",
    "# Contar valores √∫nicos en las columnas x3 y x4\n",
    "valores_x3 = df[\"x3\"].nunique()\n",
    "valores_x4 = df[\"x4\"].nunique()\n",
    "\n",
    "print(f\"Cantidad de valores diferentes en x3: {valores_x3}\")\n",
    "print(f\"Cantidad de valores diferentes en x4: {valores_x4}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff1fd37",
   "metadata": {},
   "source": [
    "\n",
    "A continuaci√≥n hago una b√∫squeda del mejor modelo de entre arboles de decision, random forests y redes neronales, cada una con sus mejores hiperpar√°metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a61a52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "df_completo = df\n",
    "\n",
    "caracteristicas_modelo = df_completo.drop(columns=[\"target\", \"x3\", \"x4\"])\n",
    "objetivo_modelo = df_completo[\"target\"]\n",
    "\n",
    "X_entrenamiento, X_prueba, y_entrenamiento, y_prueba = train_test_split(\n",
    "    caracteristicas_modelo, objetivo_modelo, test_size=0.2, random_state=42, stratify=objetivo_modelo\n",
    ")\n",
    "\n",
    "datos_entrenamiento = X_entrenamiento.copy()\n",
    "datos_entrenamiento[\"objetivo\"] = y_entrenamiento\n",
    "\n",
    "datos_minoria = datos_entrenamiento[datos_entrenamiento[\"objetivo\"] == 1]\n",
    "datos_mayoria = datos_entrenamiento[datos_entrenamiento[\"objetivo\"] == 0]\n",
    "\n",
    "datos_minoria_oversample = datos_minoria.sample(n=len(datos_mayoria), replace=True, random_state=42)\n",
    "datos_entrenamiento_balanceado = pd.concat([datos_mayoria, datos_minoria_oversample])\n",
    "datos_entrenamiento_balanceado = datos_entrenamiento_balanceado.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "X_entrenamiento_balanceado = datos_entrenamiento_balanceado.drop(columns=[\"objetivo\"])\n",
    "y_entrenamiento_balanceado = datos_entrenamiento_balanceado[\"objetivo\"]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "parametros_dt = {\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "parametros_rf = {\n",
    "    \"n_estimators\": np.arange(50, 500, 50),\n",
    "    \"max_depth\": [None, 10, 20, 30, 40],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"bootstrap\": [True, False]\n",
    "}\n",
    "\n",
    "parametros_nn = {\n",
    "    \"hidden_layer_sizes\": [(50,), (100,), (50, 50), (100, 100)],\n",
    "    \"activation\": [\"relu\", \"tanh\"],\n",
    "    \"alpha\": [0.0001, 0.001, 0.01],\n",
    "    \"solver\": [\"adam\", \"sgd\"],\n",
    "    \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "}\n",
    "\n",
    "def entrenar_modelo(modelo, parametros):\n",
    "    busqueda = RandomizedSearchCV(modelo, parametros, n_iter=20, cv=cv, scoring=\"roc_auc\", random_state=42, n_jobs=-1)\n",
    "    busqueda.fit(X_entrenamiento_balanceado, y_entrenamiento_balanceado)\n",
    "    mejor_modelo = busqueda.best_estimator_\n",
    "    \n",
    "    pred_entrenamiento = mejor_modelo.predict_proba(X_entrenamiento_balanceado)[:, 1]\n",
    "    pred_prueba = mejor_modelo.predict_proba(X_prueba)[:, 1]\n",
    "\n",
    "    auc_entrenamiento = roc_auc_score(y_entrenamiento_balanceado, pred_entrenamiento)\n",
    "    auc_prueba = roc_auc_score(y_prueba, pred_prueba)\n",
    "\n",
    "    pred_clase_prueba = (pred_prueba >= 0.5).astype(int)\n",
    "    f1_prueba = f1_score(y_prueba, pred_clase_prueba, zero_division=0)\n",
    "\n",
    "    return mejor_modelo, busqueda.best_params_, auc_entrenamiento, auc_prueba, f1_prueba\n",
    "\n",
    "modelo_dt, params_dt, auc_train_dt, auc_test_dt, f1_dt = entrenar_modelo(\n",
    "    DecisionTreeClassifier(class_weight=\"balanced\", random_state=42), parametros_dt\n",
    ")\n",
    "\n",
    "modelo_rf, params_rf, auc_train_rf, auc_test_rf, f1_rf = entrenar_modelo(\n",
    "    RandomForestClassifier(class_weight=\"balanced\", random_state=42), parametros_rf\n",
    ")\n",
    "\n",
    "modelo_nn, params_nn, auc_train_nn, auc_test_nn, f1_nn = entrenar_modelo(\n",
    "    MLPClassifier(max_iter=500, random_state=42), parametros_nn\n",
    ")\n",
    "\n",
    "resultados = {\n",
    "    \"Decision Tree\": {\"AUC Entrenamiento\": auc_train_dt, \"AUC Prueba\": auc_test_dt, \"F1 Prueba\": f1_dt, \"Hiperpar√°metros\": params_dt},\n",
    "    \"Random Forest\": {\"AUC Entrenamiento\": auc_train_rf, \"AUC Prueba\": auc_test_rf, \"F1 Prueba\": f1_rf, \"Hiperpar√°metros\": params_rf},\n",
    "    \"Neural Network\": {\"AUC Entrenamiento\": auc_train_nn, \"AUC Prueba\": auc_test_nn, \"F1 Prueba\": f1_nn, \"Hiperpar√°metros\": params_nn},\n",
    "}\n",
    "\n",
    "mejor_modelo = max(resultados, key=lambda x: resultados[x][\"AUC Prueba\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60dabbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados:\n",
      "\n",
      "Decision Tree:\n",
      "  AUC Entrenamiento: 1.0000\n",
      "  AUC Prueba: 0.4975\n",
      "  F1 Score Prueba: 0.0000\n",
      "  Mejores hiperpar√°metros: {'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n",
      "\n",
      "Random Forest:\n",
      "  AUC Entrenamiento: 1.0000\n",
      "  AUC Prueba: 0.5442\n",
      "  F1 Score Prueba: 0.0000\n",
      "  Mejores hiperpar√°metros: {'n_estimators': 250, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 30, 'bootstrap': True}\n",
      "\n",
      "Neural Network:\n",
      "  AUC Entrenamiento: 0.9700\n",
      "  AUC Prueba: 0.5770\n",
      "  F1 Score Prueba: 0.0702\n",
      "  Mejores hiperpar√°metros: {'solver': 'adam', 'learning_rate': 'constant', 'hidden_layer_sizes': (50,), 'alpha': 0.001, 'activation': 'tanh'}\n",
      "\n",
      "üèÜ Mejor modelo: Neural Network con AUC Prueba de 0.5770 y F1-score de 0.0702\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nResultados:\")\n",
    "\n",
    "for modelo, info in resultados.items():\n",
    "    print(f\"\\n{modelo}:\")\n",
    "    print(f\"  AUC Entrenamiento: {info['AUC Entrenamiento']:.4f}\")\n",
    "    print(f\"  AUC Prueba: {info['AUC Prueba']:.4f}\")\n",
    "    print(f\"  F1 Score Prueba: {info['F1 Prueba']:.4f}\")\n",
    "    print(f\"  Mejores hiperpar√°metros: {info['Hiperpar√°metros']}\")\n",
    "\n",
    "print(f\"\\nüèÜ Mejor modelo: {mejor_modelo} con AUC Prueba de {resultados[mejor_modelo]['AUC Prueba']:.4f} y F1-score de {resultados[mejor_modelo]['F1 Prueba']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9357c0ab",
   "metadata": {},
   "source": [
    "Utilic√© una grilla GridSearch para encontrar los mejores hiperpar√°metros para tres modelos de clasificaci√≥n diferentes: decision tree, random forest y multi perceptron layer (neural network/redes neuronales) y encontr√© que el mejor de ellos, es decir, el que arrojaba un valor m√°s alto de f1-score fue la red neuronal de hiperpar√°metros  {'solver': 'adam', 'learning_rate': 'constant', 'hidden_layer_sizes': (50,), 'alpha': 0.001, 'activation': 'tanh'}, donde evidentemente el f1-score debe ser lo mayor posible para poder decir que el modelo clasifica bien las dos clases. Por otro lado, intent√© hacer un oversampling y convertir las columnas x3 y x4 a variables dummies (es decir, crear variables binarias a partir de variables categoricas como aquellas), pero el f1-score se mantenia en 0 para el random forest. Por otro lado, si bien un AUC  de 57 por ciento es casi igual a un clasificador que clasifica como por azar (aleatoriamente, cuyo AUC ser√≠a de 50 por ciento), sin embargo, es preferible tener un f1-score mayor. Intent√© (fracasando) hacer un oversampling sobre la variable binaria de la columna target porque exist√≠a un desbalance totalmente absurdo, como un 1 por cada 2000 0's. Evidentemente, utilizar aqu√≠ Stratify no sirve de mucho, ni tampoco lo fue el uso de balance de clases en random forest ni en decision tree. Por lo que me quedar√≠a con el MPL (multi-perceptron layer, o multiples capas de perceptrones o red neuronal) para la clasificaci√≥n de este set de datos. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
